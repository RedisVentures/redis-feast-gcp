{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "jirdTjhETQW0"
   },
   "source": [
    "# **redis-feast-gcp**: 02 - Feature Drift\n",
    "\n",
    "In this notebook, we will use Feast SDK to load historical data and apply some simple data drift detection techniques. In practice, you will want to enable these metrics to be monitored and acted upon.\n",
    "\n",
    "**This notebook assumes that you've already set up your feature store and model repo in GCP**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![architecture](img/redis-feast-gcp-architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cJFAJiuGxM3"
   },
   "source": [
    "# Fetching Historical Data\n",
    "\n",
    "Now that our Feast feature store has been provisioned and GCP infra is ready to go, we can use Feast to generate a training dataset. To do this, we need an entity dataframe, alongside the list of features we want.\n",
    "\n",
    "To make things simpler, we use the [`DataFetcher`](utils/data_fetcher.py) class that wraps Feast, which wraps Redis and BigQuery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_store.repo import config\n",
    "from feature_store.utils import (\n",
    "    DataFetcher,\n",
    "    storage\n",
    ")\n",
    "\n",
    "# Load fs\n",
    "fs = storage.get_feature_store(\n",
    "    config_path=config.REPO_CONFIG,\n",
    "    bucket_name=config.BUCKET_NAME\n",
    ")\n",
    "\n",
    "# Load data fetcher\n",
    "data_fetcher = DataFetcher(fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Data Drift w/ Feast\n",
    "\n",
    "For data that is based on time series, it's important to consider that different windows of time behave differently due to seasonality and other temporal influences. Concept drift is very possible in these scenarios because the inference/serving (or testing) environment may be very different than the training environment.\n",
    "\n",
    "Fortunately, with an orchestration layer like **Feast** over Redis & some \"offline\" source like BigQuery, you can:\n",
    "- Measure distribution shifts in your historical data\n",
    "- Detect whether \"online\" or realtime data is \"out of bounds\" from some baseline distribution\n",
    "\n",
    "This is important in order to:\n",
    "- Make sure that training and testing windows behave similarly\n",
    "- Identify possible remedies to drift\n",
    "- Make sure that real time features and model predictions are in line"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Distribution Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def fetch_window(start, end):\n",
    "    # Fetch historical data from window\n",
    "    d = data_fetcher.get_training_data(\n",
    "        entity_query=f\"\"\"\n",
    "            select\n",
    "                state,\n",
    "                date as event_timestamp\n",
    "            from\n",
    "                {config.BIGQUERY_DATASET_NAME}.{config.WEEKLY_VACCINATIONS_TABLE}\n",
    "            where\n",
    "                date between timestamp('{start.isoformat()}') and timestamp('{end.isoformat()}')\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    # Clean up any nulls\n",
    "    d.dropna(inplace=True)\n",
    "    d.sort_values(['event_timestamp', 'state'], axis=0, inplace=True)\n",
    "    d['year'] = start.year\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and fetch windows of data\n",
    "window_1_start = datetime.strptime('2021-01-01', '%Y-%m-%d')\n",
    "window_1_end = datetime.strptime('2021-12-31', '%Y-%m-%d')\n",
    "ds_2021 = fetch_window(window_1_start, window_1_end)\n",
    "\n",
    "window_2_start = datetime.strptime('2022-01-01', '%Y-%m-%d')\n",
    "window_2_end = datetime.strptime('2022-12-31', '%Y-%m-%d')\n",
    "ds_2022 = fetch_window(window_2_start, window_2_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2021.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2022.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaccine Demand Example\n",
    "\n",
    "Given the nature of the global pandemic, we would expect there to be different underlying distributions of feature data between 2021 and 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ds_2021.lag_1_vaccine_interest, label='2021 Vaccine Search Interest')\n",
    "sns.distplot(ds_2022.lag_1_vaccine_interest, label='2022 Vaccine Search Interest')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ds_2021.lag_1_vaccine_intent, label='2021 Vaccine Search Intent')\n",
    "sns.distplot(ds_2022.lag_1_vaccine_intent, label='2022 Vaccine Search Intent')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ds_2021.lag_1_vaccine_safety, label='2021 Vaccine Search Safety')\n",
    "sns.distplot(ds_2022.lag_1_vaccine_safety, label='2022 Vaccine Search Safety')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(ds_2021.weekly_vaccinations_count, label='2021 Weekly Vaccinations Count')\n",
    "sns.distplot(ds_2022.weekly_vaccinations_count, label='2022 Weekly Vaccinations Count')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at relationships\n",
    "import pandas as pd\n",
    "\n",
    "g = sns.FacetGrid(pd.concat([ds_2021, ds_2022]), col=\"year\", height=5)\n",
    "g.map(sns.scatterplot, \"lag_2_vaccine_safety\", \"weekly_vaccinations_count\", s=100, alpha=.5)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll use a tool like evidently to cross reference data drift for all features..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.dashboard import Dashboard\n",
    "from evidently.dashboard.tabs import DataDriftTab, CatTargetDriftTab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2021['target'] = ds_2021.weekly_vaccinations_count\n",
    "ds_2022['target'] = ds_2022.weekly_vaccinations_count\n",
    "\n",
    "\n",
    "data_drift_report = Dashboard(tabs=[DataDriftTab(verbose_level=True), \n",
    "                                    CatTargetDriftTab(verbose_level=True)])\n",
    "data_drift_report.calculate(ds_2021, ds_2022, column_mapping = None)\n",
    "data_drift_report.show(mode=\"inline\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Fraud Detection Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "e1c5a7c9cc0d58080444e081b74a0823c09a12f0209aca730c38726ea6940124"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
